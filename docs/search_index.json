[
["index.html", "Road to Prediction Prerequiste", " Road to Prediction Sebastian Nickel October 06, 2018 Prerequiste This project’s goal is to predict when highways were built with the help of NASA Landsat satellite images and machine learning techniques. Everything here is work in progress. "],
["introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction I decided to test the idea of road prediction on the North-Eastern German state of Mecklenburg-Vorpommern (MV). MV is one of the “new” German states and former territory of the German Democratic Republic (GDR). In the 90s and 2000s after the former GDR territories joined the Federal Republic of Germany a lot of development projects were carried out in the new states to promote “flourishing landscapes”. Most notably in MV the motorway A20 (so-called Baltic Sea motorway) was built. I only rely on Landsat images of Landsat 4 and higher because the resolution on Landsat 1-3 is not high enough. Landsat 4 started in 1982 and the resolution for 5 of the 7 band is 30 square meters at the equator. "],
["extracting-road-data.html", "Chapter 2 Extracting road data", " Chapter 2 Extracting road data The road data for MV is extracted via the overpass API, the necessary overpass package is provided by hrbrmstr. I extract two types of roads, first the highways and then all primary roads. Especially, the second query is time consuming. library(overpass) library(rgdal) library(tidyverse) library(raster) library(sf) library(xgboost) library(keras) library(randomForest) library(data.table) library(geosampling) library(rgeos) library(knitr) library(magrittr) options(stringsAsFactors = FALSE) ## Reading layer `gadm36_DEU_1&#39; from data source `C:\\Users\\xnicse\\Dropbox\\Projects\\road_to_prediction\\data\\spatial\\gadm\\gadm36_DEU_1.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 16 features and 10 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 5.866251 ymin: 47.27012 xmax: 15.04181 ymax: 55.05653 ## epsg (SRID): 4326 ## proj4string: +proj=longlat +datum=WGS84 +no_defs Figure 2.1: Mecklenburg-Vorpommern and bounding box in red. motorway_query &lt;- &#39;[out:xml][timeout:100]; ( node[&quot;highway&quot;=&quot;motorway&quot;](53,10.5,54.7,14.5); way[&quot;highway&quot;=&quot;motorway&quot;](53,10.5,54.7,14.5); relation[&quot;highway&quot;=&quot;motorway&quot;](53,10.5,54.7,14.5); ); out body; &gt;; out skel qt;&#39; motorway_spatial &lt;- overpass_query(motorway_query) primary_query &lt;- &#39;[out:xml][timeout:100]; ( node[&quot;highway&quot;=&quot;primary&quot;](53,10.5,54.7,14.5); way[&quot;highway&quot;=&quot;primary&quot;](53,10.5,54.7,14.5); relation[&quot;highway&quot;=&quot;primary&quot;](53,10.5,54.7,14.5); ); out body; &gt;; out skel qt;&#39; primary_spatial &lt;- overpass_query(primary_query) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;C:\\Users\\xnicse\\Dropbox\\Projects\\road_to_prediction\\output\\roads_in_mv\\motorway.shp&quot;, layer: &quot;motorway&quot; ## with 2355 features ## It has 81 fields ## OGR data source with driver: ESRI Shapefile ## Source: &quot;C:\\Users\\xnicse\\Dropbox\\Projects\\road_to_prediction\\output\\roads_in_mv\\primary.shp&quot;, layer: &quot;primary&quot; ## with 9003 features ## It has 271 fields Figure 2.2: MV with motorways (red) and primary roads (blue). "],
["selecting-landsat-images.html", "Chapter 3 Selecting Landsat images 3.1 Locating the scenes 3.2 Reducing the scenes 3.3 Bulk download scenes", " Chapter 3 Selecting Landsat images Unfortunately, the NASA Landsat images need to be selected via an online mask on USGS’s webpage. My approach was to extract the identifier of the images that I want to download and then feed them into the USGS website. This way a bulk download is possible. The necessary file to identify the images can be downloaded from USGS. I only care about pictures taken between June and August by Landsat 5 which operated between 1985 and 2011. The reason is that the sizes of the images are large, including scences from the whole year means that the reflected colors change and thus, more images are necessary to train the algorithm. Additionally, clouds block the view and I assume that there are less clouds in the summer than in the winter, which increases the number of useable scenes. 3.1 Locating the scenes First, I identify the PATH and the ROW which are necessery to identify the scenes. wrs2&lt;-readOGR(&quot;data/spatial/wrs2/wrs2_descending.shp&quot;, verbose=FALSE) pol_extent2 &lt;- as(pol_extent,&quot;Spatial&quot;) %&gt;% SpatialPolygonsDataFrame(data=data.frame(x=1)) mv_wrs2 &lt;- wrs2[which(!is.na(over(wrs2,pol_extent2,returnList =FALSE))),] mv_wrs2 %&gt;% st_as_sf() %&gt;% ggplot() + geom_sf(data=mv) + geom_sf(fill=NA) Figure 3.1: MV with scenes. With the PATH and ROW numbers (Table 3.1), I turned to the eartexplorer website to search for the images. Instead of downloading the images, which are around 2 GB each, I extracted the meta file (Figure 3.2, 3.3, and 3.4). scenes &lt;- wrs2@data[which(!is.na(over(wrs2,pol_extent2,returnList =FALSE))),c(&quot;PATH&quot;,&quot;ROW&quot;)] data.frame(PATH = c(min(scenes$PATH),max(scenes$PATH)), ROW = c(min(scenes$ROW),max(scenes$ROW)),row.names = c(&quot;Min&quot;,&quot;Max&quot;)) %&gt;% kable(cap=&quot;PATH and ROW to retrieve scene list from Earthexplorer.&quot;) Table 3.1: PATH and ROW to retrieve scene list from Earthexplorer. PATH ROW Min 192 22 Max 196 23 Figure 3.2: Screenshot of selecting Landsat 4-5 from Earthexplorer. Figure 3.3: Screenshot of selecting Landsat 4-5 from Earthexplorer. Figure 3.4: Screenshot of selecting Landsat 4-5 from Earthexplorer. 3.2 Reducing the scenes The metadata can be read it and analyzed on its own. First, I only select images from Landsat 5 between June and August. I then calculate the lowest cloud coverage for each scene in each year. Third, I calculate the overal maximum of the lowest yearly coverages and the mean cloud coverare for each scene (Table 3.2). It turns out that scene 194@22 and 194@23 have the most favorable numbers and cover most of the territory of MV (Figure 3.5) images_df &lt;- read.csv(&quot;data/rectangular/scene_list/LSR_LANDSAT_TM_C1_279839.csv&quot;) %&gt;% mutate(month = strsplit(Acquisition.Date,&quot;/&quot;) %&gt;% lapply(`[[`,2) %&gt;% unlist() %&gt;% as.numeric(), year = strsplit(Acquisition.Date,&quot;/&quot;) %&gt;% lapply(`[[`,1) %&gt;% unlist() %&gt;% as.numeric(), satelitte = strsplit(Landsat.Product.Identifier,&quot;_&quot;) %&gt;% lapply(`[[`,1) %&gt;% unlist(), PATHROW = strsplit(Landsat.Product.Identifier,&quot;_&quot;) %&gt;% lapply(`[[`,3) %&gt;% unlist()) %&gt;% mutate(PATH = substr(PATHROW,1,3) %&gt;% as.numeric(), ROW = substr(PATHROW,4,6) %&gt;% as.numeric()) %&gt;% filter(month &gt; 6 &amp; month &lt; 9) %&gt;% filter(satelitte == &quot;LT05&quot;) exp &lt;- images_df %&gt;% expand(year,PATH,ROW) exp$minimum_cloud_cover &lt;- apply(exp,1,function(x) { f1 &lt;- images_df %&gt;% filter(year == x[1]&amp; PATH == x[2]&amp; ROW == x[3]) if (nrow(f1) == 0) return(NA) f1 %$% Land.Cloud.Cover %&gt;% min }) exp %&gt;% mutate(PATHROW=paste0(PATH,&quot;@&quot;,ROW)) %&gt;% group_by(PATHROW) %&gt;% summarise(`Maximum of yearly minimum cloud cover`=max(minimum_cloud_cover,na.rm=TRUE), `Mean Cloud Cover`=round(mean(minimum_cloud_cover,na.rm=TRUE),2)) %&gt;% kable(caption = &quot;Maximum and mean cloud cover for different scenes.&quot;) Table 3.2: Maximum and mean cloud cover for different scenes. PATHROW Maximum of yearly minimum cloud cover Mean Cloud Cover 192@22 97 19.22 192@23 69 17.44 193@22 100 19.74 193@23 91 23.67 194@22 74 15.31 194@23 66 14.30 195@22 77 24.07 195@23 55 21.67 196@22 100 27.19 196@23 70 29.96 ggplot() + geom_sf(data = mv) + geom_sf(data = mv_wrs2 %&gt;% st_as_sf() %&gt;% mutate(PATHROW=paste0(PATH,&quot;@&quot;,ROW)) %&gt;% filter(PATHROW %in% c(&quot;194@22&quot;,&quot;194@23&quot;)),fill=NA) Figure 3.5: Scenes 194@22 and 194@23. cloudthreshold &lt;- 50 number_of_scenes &lt;- images_df %&gt;% mutate(PATHROW=paste0(PATH,&quot;@&quot;,ROW)) %&gt;% filter(PATHROW %in% c(&quot;194@22&quot;,&quot;194@23&quot;)&amp;Land.Cloud.Cover&lt;cloudthreshold&amp;grepl(&quot;_T1&quot;,Landsat.Product.Identifier)) %&gt;% nrow I further reduce the number of scenes to only account for images with a cover less than 50%. A total of 79 are still being considered. Figure 3.6 shows the distribution of cloud covers for both scenes from 1984 to 2011. images_df %&gt;% mutate(PATHROW=paste0(PATH,&quot;@&quot;,ROW)) %&gt;% filter(PATHROW %in% c(&quot;194@22&quot;,&quot;194@23&quot;)&amp;Land.Cloud.Cover&lt;cloudthreshold&amp;grepl(&quot;_T1&quot;,Landsat.Product.Identifier)) %&gt;% ggplot() + geom_point(aes(x=year,y=Land.Cloud.Cover,group=PATHROW,color=PATHROW)) + ylab(&quot;Area covered by clouds&quot;) + xlab(&quot;Year&quot;) + scale_color_discrete(name=&quot;Scenes&quot;) Figure 3.6: Scenes 3.3 Bulk download scenes images_df %&gt;% mutate(PATHROW=paste0(PATH,&quot;@&quot;,ROW)) %&gt;% filter(PATHROW %in% c(&quot;194@22&quot;,&quot;194@23&quot;)&amp;Land.Cloud.Cover&lt;cloudthreshold&amp;grepl(&quot;_T1&quot;,Landsat.Product.Identifier)) %&gt;% dplyr::select(Landsat.Product.Identifier) %&gt;% fwrite(&quot;scene_list.csv&quot;,col.names = FALSE) The list needs to be uploaded on Earthexplorer. Figure 3.7: Screenshot of Earthexplorer mask. Once the scenes are ready, I copied the source code of the website and extracted the urls to the files since they are not directly password protected. Then I downloaded them and untarred them. website &lt;- readLines(&quot;data/landsatwebsite/website&quot;,warn=FALSE) urls &lt;- website[grep(&quot;Download&lt;/a&gt;&quot;,website)] %&gt;% strsplit(&quot;&gt;&quot;) %&gt;% lapply(`[[`,1) %&gt;% unlist() %&gt;% gsub(&quot;&lt;a href=\\&quot;&quot;,&quot;&quot;,.) %&gt;% gsub(&quot;\\&quot;&quot;,&quot;&quot;,.) %&gt;% gsub(&quot; &quot;,&quot;&quot;,.) save_files &lt;- urls %&gt;% strsplit(&quot;/&quot;) %&gt;% lapply(`[[`,6) %&gt;% unlist() sapply(1:length(urls),function(x) { download.file(url = urls[x], destfile = paste0(&quot;E:/landsatscene/&quot;,save_files[x])) }) tar_files &lt;- list.files(&quot;E:/landsatscene/&quot;,full.names = TRUE) sapply(tar_files,function(x) { if (file.exists(x %&gt;% gsub(&quot;.tar.gz&quot;,&quot;&quot;,.))) return() untar(x,exdir = x %&gt;% gsub(&quot;.tar.gz&quot;,&quot;&quot;,.)) }) "],
["basic-analysis.html", "Chapter 4 Basic Analysis", " Chapter 4 Basic Analysis First, I will look at one satellite picture to show the general procedure. According to the Landsat website the pixel_qa band has a more accurate prediction for identifying clouds, cloud shadows, water, and snow. Rcpp::sourceCpp(&quot;cppsource/table_cpp.cpp&quot;) cloud_identification &lt;- raster(&quot;E:/landsatscene/LT051940232011072701T1-SC20180926185810/LT05_L1TP_194023_20110727_20180312_01_T1_pixel_qa.tif&quot;) cloud_identification_cropped &lt;- crop(cloud_identification,st_transform(mv,crs=proj4string(cloud_identification))) mv_raster &lt;- fasterize::fasterize(st_transform(mv,crs=proj4string(cloud_identification)),cloud_identification_cropped) cloud_identification_masked &lt;- mask(cloud_identification_cropped,mv_raster) cloud_identification_values &lt;- getValues(cloud_identification_masked) none_clear_values &lt;- c(96, 112, 160, 176, 224, 68, 72, 80, 96, 112, 132, 136, 144, 160, 176,224,72, 136,68, 132,80, 112, 144, 176) cloud_identification_values_2 &lt;- ifelse(cloud_identification_values %in% none_clear_values,0, ifelse(is.na(cloud_identification_values),NA,1)) cloud_identification_2 &lt;- setValues(cloud_identification_masked,cloud_identification_values_2) cbind(table_cpp(cloud_identification_values_2[!is.na(cloud_identification_values_2)]) %&gt;% do.call(rbind,.),c(sum(is.na(cloud_identification_values_2)),NA)) %&gt;% t %&gt;% as.data.frame %&gt;% mutate(lengths = 100*lengths/sum(lengths)) %&gt;% rename(Percentage = lengths, Values = values) %&gt;% kable(caption=&quot;Coverage for different values. `NA` are the rims of the picture, 0 is cloud covered, and 1 is free sight.&quot;) Table 4.1: Coverage for different values. NA are the rims of the picture, 0 is cloud covered, and 1 is free sight. Percentage Values 28.96906 0 28.16872 1 42.86222 NA motorways_sf &lt;- spTransform(motorways,CRS(proj4string(cloud_identification_2))) %&gt;% gBuffer(width = 1) %&gt;% st_as_sf() motorways_raster &lt;- fasterize::fasterize(motorways_sf, cloud_identification_2) covered_by_road &lt;- mask(cloud_identification_2,motorways_raster) %&gt;% getValues() %&gt;% is.na() %&gt;% `!` %&gt;% which() cloud_identification_values_3 &lt;- ifelse(is.na(cloud_identification_values_2),0,cloud_identification_values_2) listed_raster &lt;- list.files(&quot;E:/landsatscene/LT051940232011072701T1-SC20180926185810/&quot;,pattern=&quot;band[0-9].tif$&quot;,full.names = TRUE) values_df &lt;- lapply(listed_raster,function(ra1_path) { ra1 &lt;- raster(ra1_path) ra1_cropped &lt;- crop(ra1,st_transform(mv,crs=proj4string(ra1))) ra1_cropped_masked &lt;- mask(ra1_cropped,mv_raster) ra1_cropped_masked_cloudless &lt;- setValues(ra1_cropped_masked,ifelse(getValues(ra1_cropped_masked)*cloud_identification_values_3==0,NA,getValues(ra1_cropped_masked))) getValues(ra1_cropped_masked_cloudless) }) %&gt;% do.call(cbind,.) %&gt;% as.data.frame() values_df$motorway &lt;- 0 values_df$motorway[covered_by_road] &lt;- 1 identify_na &lt;- sapply(paste0(&quot;V&quot;,1:6),function(x) { values_df[,x] %&gt;% is.na() %&gt;% which() }) %&gt;% unlist() %&gt;% unique() if (length(identify_na) &gt; 0) { values_df &lt;- values_df %&gt;% dplyr::slice(-identify_na) } norm_mean &lt;- function(x) { (x-mean(x))/(max(x)-min(x)) } values_df[,paste0(&quot;V&quot;,1:6)] &lt;- values_df[,paste0(&quot;V&quot;,1:6)] %&gt;% apply(2,norm_mean) train_and_test_data &lt;- function(seed,df,trainsize=0.8, replace_motorway=TRUE, sample_size=1e4, sample_test=1e4) { set.seed(seed) df$motorway &lt;- as.factor(df$motorway) motorway_pixel &lt;- which(df$motorway==1) no_motorway_pixel &lt;- which(df$motorway==0) sampled_motorway_pixel &lt;- sample(motorway_pixel, round(trainsize*length(motorway_pixel))) sampled_no_motorway_pixel &lt;- sample(no_motorway_pixel, round(trainsize*length(no_motorway_pixel))) test_motorway_pixel &lt;- motorway_pixel[!motorway_pixel %in% sampled_motorway_pixel] test_no_motorway_pixel &lt;- no_motorway_pixel[!no_motorway_pixel %in% sampled_no_motorway_pixel] values_df_train &lt;- df[c(sampled_motorway_pixel,sampled_no_motorway_pixel),] values_df_test &lt;- df[c(test_motorway_pixel,test_no_motorway_pixel),] # train if (replace_motorway) { selected_motorway &lt;- sample(sampled_motorway_pixel,sample_size,replace=TRUE) selected_non_motorway &lt;- sample(sampled_no_motorway_pixel,sample_size) } else { selected_motorway &lt;- sampled_motorway_pixel selected_non_motorway &lt;- sample(sampled_no_motorway_pixel,sample_size) } subset &lt;- c(selected_non_motorway,selected_motorway) values_df_model &lt;- dplyr::slice(values_df,subset) # test subset_test &lt;- c(test_motorway_pixel,sample(test_no_motorway_pixel, sample_test)) values_df_test &lt;- dplyr::slice(values_df,subset_test) list(train=values_df_model, test=values_df_test) } set.seed(15) random_number &lt;- sample(1e5,100) generated &lt;- lapply(random_number,function(x) { train_test_list &lt;- train_and_test_data(seed = x, df = values_df, trainsize = 0.8, sample_size = 1e4, sample_test = 1e4) values_df_model &lt;- train_test_list$train values_df_test &lt;- train_test_list$test # model model_linear &lt;- lm(motorway~V1+V2+V3+V4+V5+V6,data=values_df_model) # predict values_df_test$predicted &lt;- predict(model_linear,values_df_test) values_df_test &lt;- values_df_test %&gt;% mutate(predicted_binary = as.numeric(predicted&gt;0.5), equal = as.numeric(motorway==predicted_binary)) values_df_test %&gt;% dplyr::rename(Type=motorway) %&gt;% group_by(Type) %&gt;% summarise(Value = sum(equal)/n()) %&gt;% mutate(Type=ifelse(Type==1,&quot;motorway_accuracy&quot;,&quot;none_motorway_accuracy&quot;)) }) %&gt;% do.call(rbind,.) generated_rf &lt;- lapply(random_number,function(x) { values_df$motorway &lt;- as.factor(values_df$motorway) train_test_list &lt;- train_and_test_data(seed = x, df = values_df, trainsize = 0.8, replace_motorway = FALSE, sample_size = 1e3, sample_test = 1e4) values_df_model &lt;- train_test_list$train values_df_test &lt;- train_test_list$test # train model_rf&lt;-randomForest( formula = motorway~V1+V2+V3+V4+V5+V6, data= values_df_model, ntree=500, importance=TRUE)#, # predict values_df_test$predicted &lt;- predict(model_rf,values_df_test %&gt;% dplyr::select(paste0(&quot;V&quot;,1:6),motorway)) values_df_test2 &lt;- values_df_test %&gt;% mutate(equal = as.numeric(motorway==predicted)) values_df_test2 %&gt;% dplyr::rename(Type=motorway) %&gt;% group_by(Type) %&gt;% summarise(Value = sum(equal)/n()) %&gt;% mutate(Type=ifelse(Type==1,&quot;motorway_accuracy&quot;,&quot;none_motorway_accuracy&quot;)) }) %&gt;% do.call(rbind,.) generated_xgb &lt;- lapply(random_number,function(x) { train_test_list &lt;- train_and_test_data(seed = x, df = values_df, trainsize = 0.8, replace_motorway = FALSE, sample_size = 1e3, sample_test = 1e4) values_df_model &lt;- train_test_list$train values_df_test &lt;- train_test_list$test train_dat&lt;-xgb.DMatrix( data = values_df_model %&gt;% dplyr::select(paste0(&quot;V&quot;,1:6)) %&gt;% as.matrix(), label = values_df_model %&gt;% dplyr::select(motorway) %&gt;% unlist) model_xgboost&lt;-xgboost(data = train_dat, # the data nrounds=1000, eta=0.025, subsample=0.63, lamba=0.001, objective = &quot;binary:logistic&quot;) test_dat&lt;-xgb.DMatrix( data = values_df_test %&gt;% dplyr::select(paste0(&quot;V&quot;,1:6)) %&gt;% as.matrix(), label = values_df_test %&gt;% dplyr::select(motorway) %&gt;% unlist) values_df_test$predicted &lt;- predict(model_xgboost,test_dat) values_df_test2 &lt;- values_df_test %&gt;% mutate(predicted_binary = as.numeric(predicted&gt;0.5), equal = as.numeric(motorway==predicted_binary)) values_df_test2 %&gt;% dplyr::rename(Type=motorway) %&gt;% group_by(Type) %&gt;% summarise(Value = sum(equal)/n()) %&gt;% mutate(Type=ifelse(Type==1,&quot;motorway_accuracy&quot;,&quot;none_motorway_accuracy&quot;)) }) %&gt;% do.call(rbind,.) generated_keras &lt;- lapply(random_number,function(x) { train_test_list &lt;- train_and_test_data(seed = x, df = values_df, trainsize = 0.8, replace_motorway = TRUE, sample_size = 2e4, sample_test = 1e4) values_df_model &lt;- train_test_list$train values_df_test &lt;- train_test_list$test model &lt;- keras_model_sequential() model %&gt;% layer_dense(units = 256, activation = &#39;elu&#39;, input_shape = c(6),kernel_regularizer = regularizer_l2(0.001)) %&gt;% layer_dense(units = 128, activation = &#39;elu&#39;, input_shape = c(6),kernel_regularizer = regularizer_l2(0.001)) %&gt;% layer_dense(units = 64, activation = &#39;elu&#39;, input_shape = c(6),kernel_regularizer = regularizer_l2(0.0001)) %&gt;% layer_dense(units = 32, activation = &#39;elu&#39;, input_shape = c(6),kernel_regularizer = regularizer_l2(0.0001)) %&gt;% layer_dense(units = 16,activation = &#39;elu&#39;, input_shape = c(6),kernel_regularizer = regularizer_l2(0.0001)) %&gt;% layer_dense(units = 8, activation = &#39;elu&#39;, kernel_regularizer = regularizer_l2(0.0001)) %&gt;% layer_dense(units = 4, activation = &#39;elu&#39;, kernel_regularizer = regularizer_l2(0.0001)) %&gt;% layer_dense(units = 3, activation = &#39;elu&#39;, kernel_regularizer = regularizer_l2(0.0001)) %&gt;% layer_dense(units = 2, activation = &#39;sigmoid&#39;) model %&gt;% compile( loss = &#39;binary_crossentropy&#39;, #loss = &#39;categorical_crossentropy&#39;, # optimizer= &#39;rmsprop&#39;, optimizer = &#39;adam&#39;, metrics = c(&#39;accuracy&#39;)) k_set_value(model$optimizer$lr, 0.00001) k_set_value(model$optimizer$decay, 0.00001/100) history &lt;- model %&gt;% fit( x = values_df_model %&gt;% dplyr::select(paste0(&quot;V&quot;,1:6)) %&gt;% apply(2,as.numeric), y = values_df_model %&gt;% dplyr::select(motorway) %&gt;% apply(2,as.numeric)%&gt;% to_categorical(), epochs = 60, batch_size = 30, validation_split = 0.1) predicted &lt;- model %&gt;% predict(values_df_test %&gt;% dplyr::select(paste0(&quot;V&quot;,1:6)) %&gt;% apply(2,as.numeric)) values_df_test$predicted &lt;- predicted[,2] values_df_test2 &lt;- values_df_test %&gt;% mutate(predicted_binary = as.numeric(predicted&gt;0.5), equal = as.numeric(motorway==predicted_binary)) values_df_test2 %&gt;% dplyr::rename(Type=motorway) %&gt;% group_by(Type) %&gt;% summarise(Value = sum(equal)/n()) %&gt;% mutate(Type=ifelse(Type==1,&quot;motorway_accuracy&quot;,&quot;none_motorway_accuracy&quot;)) }) %&gt;% do.call(rbind,.) list.files(&quot;output/one_scene_model_eval/&quot;,full.names=TRUE) %&gt;% lapply(function(x) { dat &lt;- read.csv(x) dat$Estimator &lt;- x %&gt;% strsplit(&quot;/&quot;) %&gt;% lapply(`[`,3) %&gt;% unlist %&gt;% gsub(&quot;.csv&quot;,&quot;&quot;,.) dat }) %&gt;% do.call(rbind,.) %&gt;% ggplot() + geom_violin(aes(x=Type,y=Value,fill=Estimator)) "],
["open-questionsissues.html", "Chapter 5 Open Questions/Issues", " Chapter 5 Open Questions/Issues Does it travel to Landsat 7 or even 8? Does it travel geographically to other areas? built in to create a tiff again in general built pipeline to assess if part of road exists or not. CNN? "]
]
